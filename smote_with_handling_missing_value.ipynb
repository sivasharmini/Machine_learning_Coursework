{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"##### # Imports\n\n# Pandas and numpy for data manipulation\nimport pandas as pd\nimport numpy as np\n\n# No warnings about setting value on copy of slice\npd.options.mode.chained_assignment = None\n\n# Display up to 60 columns of a dataframe\npd.set_option('display.max_columns', 60)\n\n# Matplotlib visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Set default font size\nplt.rcParams['font.size'] = 24\n\n# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\n\n# Seaborn for visualization\nimport seaborn as sns\nsns.set(font_scale = 2)\n\n# Splitting data into training and testing\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression,LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # # Data Cleaning and Formatting\n\n# # Load in the Data and Examine\n\n# Read in credit into a dataframe \ncredit = pd.read_csv('../input/my-dataset/credit_train.csv')\n\n# Display top of dataframe\ncredit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handling NA vs Changing the type of Feilds**\n\nAlways Make sure that ,You should handle Null values in Data on first priority and the typecase them into some categories or in some other form.\nLets Find out the Row level Duplicate and Remove them ,Because they are of no Use to us.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for all Row level NULL(It means all column values for that row are null) from Dataframe because they are not carring any information.\ncredit=credit[credit.isna().all(axis=1)==False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check whether Row level NULL are hablded or Not\ncredit.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, it looks like some of the credit score are just scaled up by 10. For the ease of our calculation we can consider, scaling them back is accurate."},{"metadata":{"trusted":true},"cell_type":"code","source":"credit.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Data Types and Missing Values\n\n# See the column data types and non-missing values\ncredit.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistics for each column\ncredit.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit.drop(labels=['Loan ID', 'Customer ID'], axis=1, inplace=True)\n\n# These two features are only for identification.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**hANDLINF CATEGORICAL FEATURES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"credit['Loan Status'] = credit['Loan Status'].map({'Fully Paid':int('0'),'Charged Off':int('1')})\ncredit['Term'] = credit['Term'].map({'Short Term':int('0'),'Long Term':int('1')})\ncredit['Years in current job'] = credit['Years in current job'].map({'< 1 year':int('0'),'1 year':int('1'),'2 years':int('2'),'3 years':int('3'),'4 years':int('4'),'5 years':int('5'),'6 years':int('6'),'7 years':int('7'),'8 years':int('8'),'9 years':int('9'),'10+ years':int('10')})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del(credit['Months since last delinquent'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Encoding categorical data & Feature Scaling\n\n# Select the categorical columns\ncategorical_subset = credit[['Home Ownership', 'Purpose']]\n\n# One hot encode\ncategorical_subset = pd.get_dummies(categorical_subset)\n\n# Join the dataframe in credit_train\n# Make sure to use axis = 1 to perform a column bind\n# First I will drop the 'old' categorical datas and after I will join the 'new' one.\n\ncredit.drop(labels=['Home Ownership', 'Purpose'], axis=1, inplace=True)\ncredit = pd.concat([credit, categorical_subset], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Missing Values\n\n# Function to calculate missing values by column\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_table(credit)\n\n# A curious thing about the table below is the last 10 features have the same number o missing values.\n# I will go deeper and figure out what is happening.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Handling missing value with correlation methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = credit.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(corr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr['Credit Score'][abs(corr['Credit Score']) > 0.1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr['Annual Income'][abs(corr['Annual Income']) > 0.1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr['Years in current job'][abs(corr['Years in current job']) > 0.1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr['Bankruptcies'][abs(corr['Bankruptcies']) > 0.1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr['Tax Liens'][abs(corr['Tax Liens']) > 0.1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr['Maximum Open Credit'][abs(corr['Maximum Open Credit']) > 0.1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit_without_mv = credit.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1_col = ['Loan Status']\ny1 = credit_without_mv['Credit Score']\nx1 = credit_without_mv['Loan Status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1 = y1.values.reshape(77271,1)\nx1 = x1.values.reshape(77271,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linreg1 = LinearRegression()\nlinreg1.fit(x1,y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit['Credit Score'] = credit.apply(lambda x:linreg1.predict(x['Loan Status'].reshape(1,1))[0][0] if np.isnan(x['Credit Score']) else x['Credit Score'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credit['Credit Score'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for Annual income\n\nx2_col = ['Monthly Debt', 'Years of Credit History', 'Number of Open Accounts', 'Current Credit Balance', 'Home Ownership_Home Mortgage', 'Home Ownership_Rent']\ny2 = credit_without_mv['Annual Income']\nx2 = credit_without_mv[x2_col]\ny2 = y2.values.reshape(77271,1)\nx2 = x2.values.reshape(77271,6)\nlinreg2 = LinearRegression()\nlinreg2.fit(x2,y2)\ncredit['Annual Income'] = credit.apply(lambda x:linreg2.predict(x[x2_col].values.reshape(1,6))[0][0] if np.isnan(x['Annual Income']) else x['Annual Income'], axis =1)\ncredit['Annual Income'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for Years in current job\n\nx3_col = ['Monthly Debt', 'Years of Credit History', 'Home Ownership_Home Mortgage', 'Home Ownership_Rent']\ny3 = credit_without_mv['Years in current job']\nx3 = credit_without_mv[x3_col]\ny3 = y3.values.reshape(77271,1)\nx3 = x3.values.reshape(77271,4)\nlinreg3 = LogisticRegression()\nlinreg3.fit(x3,y3)\ncredit['Years in current job'] = credit.apply(lambda x:linreg3.predict(x[x3_col].values.reshape(1,4))[0:4][0] if np.isnan(x['Years in current job']) else x['Years in current job'], axis =1)\ncredit['Years in current job'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for Maximum Open Credit\n\ny4 = credit_without_mv['Maximum Open Credit']\nx4 = credit_without_mv['Current Credit Balance']\ny4 = y4.values.reshape(77271,1)\nx4 = x4.values.reshape(77271,1)\nlinreg4 = LinearRegression()\nlinreg4.fit(x4,y4)\ncredit['Maximum Open Credit'] = credit.apply(lambda x:linreg4.predict(x['Current Credit Balance'].reshape(1,1))[0][0] if np.isnan(x['Maximum Open Credit']) else x['Maximum Open Credit'], axis =1)\ncredit['Maximum Open Credit'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for Bankruptcies\n\nx5_col = ['Current Credit Balance', 'Number of Credit Problems']\ny5 = credit_without_mv['Bankruptcies']\nx5 = credit_without_mv[x5_col]\ny5 = y5.values.reshape(77271,1)\nx5 = x5.values.reshape(77271,2)\nlinreg5 = LinearRegression()\nlinreg5.fit(x5,y5)\ncredit['Bankruptcies'] = credit.apply(lambda x:linreg5.predict(x[x5_col].values.reshape(1,2))[0][0] if np.isnan(x['Bankruptcies']) else x['Bankruptcies'], axis =1)\ncredit['Bankruptcies'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for tax liens\n\ny6 = credit_without_mv['Tax Liens']\nx6 = credit_without_mv['Number of Credit Problems']\ny6 = y6.values.reshape(77271,1)\nx6 = x6.values.reshape(77271,1)\nlinreg6 = LinearRegression()\nlinreg6.fit(x6,y6)\ncredit['Tax Liens'] = credit.apply(lambda x:linreg6.predict(x['Number of Credit Problems'].reshape(1,1))[0][0] if np.isnan(x['Tax Liens']) else x['Tax Liens'], axis =1)\ncredit['Tax Liens'].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# End hadling missing value using correlation"},{"metadata":{},"cell_type":"markdown","source":"**start SMOTE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score, roc_auc_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport math\n\ndef generate_model_report(y_actual, y_predicted):\n    \n    conf_mat = confusion_matrix(y_actual, y_predicted) \n    true_positive = conf_mat[1,1]\n    true_negative = conf_mat[0,0]\n    false_positive = conf_mat[0,1]\n    false_negative = conf_mat[1,0]\n    specificity = (true_negative)/(true_negative + false_positive)\n    gm = math.sqrt(specificity * recall_score(y_actual, y_predicted))\n    \n    print(\"Accuracy = \" , accuracy_score(y_actual, y_predicted))\n    print(\"Precision = \" ,precision_score(y_actual, y_predicted))\n    print(\"Recall/Sensitivity = \" ,recall_score(y_actual, y_predicted))\n    print(\"Specificity = \" ,specificity)\n    print(\"F1 Score = \" ,f1_score(y_actual, y_predicted))\n    print(\"ROC-AUC Score = \" ,roc_auc_score(y_actual, y_predicted))\n    print(\"G-Measure = \" ,gm)\n    \n    sns.heatmap(conf_mat,cmap=\"coolwarm_r\", annot=True,linewidths=0.5,fmt='g')\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted value\")\n    plt.ylabel(\"Actual label\")\n    plt.show()\n    pass\n\ndef generate_auc_roc_curve(clf, X_test):\n    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n    fpr, tpr, thresholds = roc_curve(Y_test,  y_pred_proba)\n    auc = roc_auc_score(Y_test, y_pred_proba)\n    plt.plot(fpr,tpr,label=\"AUC =\"+str(auc))\n    plt.legend(loc=4)\n    plt.show()\n    pass\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = credit.loc[:, credit.columns!='Loan Status']\n\nY = credit.loc[:, credit.columns=='Loan Status']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n                                                    test_size=0.2, \n                                                    random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Encoding the Dependent Variable\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder_y_train = LabelEncoder()\nY_train = labelencoder_y_train.fit_transform(Y_train)\nlabelencoder_y_test = LabelEncoder()\nY_test = labelencoder_y_test.fit_transform(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import make_pipeline\nsm = SMOTE(random_state=12, ratio = 1.0)\nx_train_res, y_train_res = sm.fit_sample(X_train, Y_train)\n\nunique, count = np.unique(y_train_res, return_counts=True)\ny_train_smote_value_count = { k:v for (k,v) in zip(unique, count)}\ny_train_smote_value_count\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"logistic regression\")\nclf = LogisticRegression().fit(x_train_res, y_train_res)\nY_Test_Pred = clf.predict(X_test)\ngenerate_model_report(Y_test, Y_Test_Pred)\ngenerate_auc_roc_curve(clf, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nprint(\"KNN\")\n\nclf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2).fit(x_train_res, y_train_res)\nY_Test_Pred = clf.predict(X_test)\ngenerate_model_report(Y_test, Y_Test_Pred)\ngenerate_auc_roc_curve(clf, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nprint(\"Decision Tree\")\n\nclf = tree.DecisionTreeClassifier(random_state=1).fit(x_train_res, y_train_res)\nY_Test_Pred = clf.predict(X_test)\ngenerate_model_report(Y_test, Y_Test_Pred)\ngenerate_auc_roc_curve(clf, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Naive bayes\")\nfrom sklearn.naive_bayes import GaussianNB\n\nclf = GaussianNB().fit(x_train_res, y_train_res)\nY_Test_Pred = clf.predict(X_test)\ngenerate_model_report(Y_test, Y_Test_Pred)\ngenerate_auc_roc_curve(clf, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Random forest\")\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nclf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy').fit(x_train_res, y_train_res)\nY_Test_Pred = clf.predict(X_test)\ngenerate_model_report(Y_test, Y_Test_Pred)\ngenerate_auc_roc_curve(clf, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"XGBoost\")\nfrom xgboost import XGBClassifier\n\nclf = XGBClassifier().fit(x_train_res, y_train_res)\nY_Test_Pred = clf.predict(X_test)\ngenerate_model_report(Y_test, Y_Test_Pred)\ngenerate_auc_roc_curve(clf, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # # Models to Evaluate\n\n# We will compare five different machine learning Classification models:\n\n# 1 - Logistic Regression\n# 2 - K-Nearest Neighbors Classification\n# 3 - Suport Vector Machine\n# 4 - Naive Bayes\n# 5 - Random Forest Classification\n\n# Function to calculate mean absolute error\ndef cross_val(X_train, y_train, model):\n    # Applying k-Fold Cross Validation\n    from sklearn.model_selection import cross_val_score\n      \n    accuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10, verbose = 2)\n    return accuracies.mean()\n\n\ndef confusion_metrix(X_train, y_train, model):\n    \n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import accuracy_score\n    from sklearn.metrics import precision_score, recall_score\n    from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n    import math\n    \n    ## confusion metrix \n    from sklearn.metrics import confusion_matrix\n    y_pred = cross_val_predict(model, X_train, y_train, cv=3)\n    conf_mat = confusion_matrix(y_train, y_pred) \n    true_positive = conf_mat[1,1]\n    true_negative = conf_mat[0,0]\n    false_positive = conf_mat[0,1]\n    false_negative = conf_mat[1,0]\n    specificity = (true_negative)/(true_negative + false_positive)\n    gm = math.sqrt(specificity * recall_score(y_train, y_pred))\n    \n   \n\n    print(\"Accuracy = \" , accuracy_score(y_train, y_pred))\n    print(\"Precision = \" ,precision_score(y_train, y_pred))\n    print(\"Recall/ Sensitivity = \" ,recall_score(y_train, y_pred))\n    print(\"Specificity = \" ,specificity)\n    print(\"F1 Score = \" ,f1_score(y_train, y_pred))\n    print(\"ROC-AUC Score = \" ,roc_auc_score(y_train, y_pred))\n    print(\"G-Measure = \" ,gm)\n    return conf_mat\n\n\n# Takes in a model, trains the model, and evaluates the model on the test set\ndef fit_and_evaluate(model):\n    \n    # Train the model\n    #model.fit(X_train, y_train)\n    \n    # Make predictions and evalute\n    #model_pred = model.predict(X_test)\n    model_acc_cross = cross_val(x_train_res, y_train_res, model)\n    print (\"print accuracy is \",model_acc_cross)\n    \n    con_matrix = confusion_metrix(x_train_res, y_train_res, model)\n    print (\"print confusion metrix is \",con_matrix)\n    sns.heatmap(con_matrix,cmap=\"coolwarm_r\", annot=True,linewidths=0.5,fmt='g')\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted value\")\n    plt.ylabel(\"Actual label\")\n    plt.show()\n\n    \n    # Return the performance metric\n    return model_acc_cross","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogr = LogisticRegression()\nlogr_cross = fit_and_evaluate(logr)\n\nprint('Logistic Regression Performance on the test set: Cross Validation Score = %0.4f' % logr_cross)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # K-NN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn_cross = fit_and_evaluate(knn)\n\nprint('KNN Performance on the test set: Cross Validation Score = %0.4f' % knn_cross)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nnaive = GaussianNB()\nnaive_cross = fit_and_evaluate(naive)\n\nprint('Naive Bayes Performance on the test set: Cross Validation Score = %0.4f' % naive_cross)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # Random Forest Classification\nfrom sklearn.ensemble import RandomForestClassifier\nrandom = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\nrandom_cross = fit_and_evaluate(random)\n\nprint('Random Forest Performance on the test set: Cross Validation Score = %0.4f' % random_cross)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Gradiente Boosting Classification\nfrom xgboost import XGBClassifier\ngb = XGBClassifier()\ngb_cross = fit_and_evaluate(gb)\n\nprint('Gradiente Boosting Classification Performance on the test set: Cross Validation Score = %0.4f' % gb_cross)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Decision tree\nfrom sklearn import tree\ndt = tree.DecisionTreeClassifier(random_state=1) \ndt_cross = fit_and_evaluate(dt)\n\nprint('Decision tree Performance on the test set: Cross Validation Score = %0.4f' % dt_cross)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}